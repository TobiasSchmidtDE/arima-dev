1. Java 
=======
The Java version should be > 1.8.

   $ java -version

Set JAVA_HOME environment variable, 

   $ export JAVA_HOME="$(/usr/libexec/java_home)"

2. Spark
========
Download Spark from https://spark.apache.org/downloads.html and move
to home directory, and extract.

   $ tar -xzf spark-2.1.0-bin-hadoop2.7.tgz

and set environment variables to point to the extracted directory,

   $ export SPARK_HOME="$HOME/spark-2.1.0-bin-hadoop2.7"
   $ export HADOOP_HOME=$SPARK_HOME
   $ export SPARK_LOCAL_IP=127.0.0.1

3. Python, Jupyter, and other libraries 
=======================================
Download and install Anaconda Python 2.7 from https://www.continuum.io/downloads#macos
(includes jupyter, and pip)

   $ export PYSPARK_DRIVER_PYTHON=jupyter
   $ export PYSPARK_DRIVER_PYTHON_OPTS='notebook' pyspark

Download and install Graphviz.

   $ brew install graphviz

For Fedora/RHEL users: $ yum install 'graphviz*'
For Ubuntu users:      $ sudo apt-get install graphviz

4. Apache SystemML
==================
cd to tutorial folder, and install this version of Apache SystemML,  

   $ pip install ./systemml-1.0.0-SNAPSHOT-python.tgz

and start pyspark/Jupyter

   $ $SPARK_HOME/bin/pyspark --master local[*] --driver-memory 8G
